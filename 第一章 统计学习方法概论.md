本章简要叙述统计学习方法的一些基本概念。

- 统计学习的定义、研究对象与方法
- 监督学习（本书主要内容）
- 统计学习方法的三要素：模型、策略和算法
- 模型选择，包括正则化、交叉验证与学习的泛化能力
- 生成模型与判别模型
- 监督学习方法的应用：分类问题、标注问题与回归问题

[TOC]

## 1. 统计学习

### 1.1 特点

统计学习（statistical learning）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科，统计学习也称为统计机器学习（statistical machine learning）。

主要特点：

1. 统计学习以计算机及网络为平台，是建立在计算机及网络之上的。
2. 统计学习以数据为研究对象，是数据驱动的学科。
3. 统计学习的目的是对数据进行预测和分析。
4. 统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析。
5. 统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论。

赫尔伯特·西蒙（Herbert A. Simon）对"学习"给出以下定义：如果一个系统能够通过执行某个过程改进它的性能，这就是学习。

由此，可以得出：

> 统计学习就是计算机系统通过运用数据及统计方法提高系统性能的机器学习

### 1.2 统计学习的对象

统计学习的对象是数据（data），它从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。

作为统计学习的对象，数据是多样的，包括存在于计算机及网络上的各种数字、文字、图像、视频、音频数据以及它们的组合。

统计学习关于数据的基本假设是**同类数据**具有一定的统计规律性，这是统计学习的前提。

>同类数据：指具有某种共同性质的数据，例如英文文章、互联网网页、数据库中的数据等。
>
>由于他们具有统计规律性，所以可以用概率统计方法来加以处理。
>
>比如，可以用随机变量描述数据中的特征，用概率分布描述数据的统计规律。

在统计学习过程中，以变量或变量组表示数据。

数据分为有连续变量和离散变量表示的类型，本书以讨论离散变量的方法为主。

### 1.3 统计学习的目的

统计学习用于对数据进行预测和分析，特别是对未知新数据进行预测与分析。

对数据的预测可以使计算机更加智能化，或者说使计算机的某些性能得到提高。

对数据的分析可以让人们获取新的知识，给人们带来新的发现。

对数据的预测与分析是通过构建概率统计模型实现的。

统计学习的总目标就是：考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。

### 1.4 统计学习的方法

统计学习的方法是基于数据构建统计模型从而对数据进行预测与分析。

统计学习的组成：

- 监督学习（supervised learning）
- 无监督学习（unsupervised learning）
- 半监督学习（semi-supervised learning）
- 强化学习（reinforcement learning）

本书主要讨论监督学习，这种情况下统计学习的方法可以概括如下：

- 从给定的、有限的、用于学习的训练数据（training data）集合出发，假设数据是独立同分布产生的
- 假设要学习的模型属于某个函数的集合，称为假设空间（hypothesis space）
- 应用某个评价准则（evaluation criterion），从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据（test data）在给定的评价准则下有最优的预测
- 最优模型的选取由算法实现

统计学习方法的三要素：模型model（模型的假设空间）、策略strategy（模型选择的准则）、算法algorithm（模型学习的算法）

实现统计学习方法的步骤：

1. 得到一个有限的训练数据集合
2. 确定包含所有可能的模型的假设空间，即学习模型的集合
3. 确定模型选择的准则，即学习的策略
4. 实现求解最优模型的算法，即学习的算法
5. 通过学习方法选择最优模型
6. 利用学习的最优模型对新数据进行预测或分析

本书主要介绍统计学习方法为主，特别是监督学习方法，主要包括用于分类、标注与回归问题的方法。

这些方法在自然语言处理、信息检索、文本数据挖掘等领域中有着极其广泛的应用。

### 1.5 统计学习的研究

统计学习研究包括三个方面：

- 统计学习方法（statistical learning method）：开发新的学习方法
- 统计学习理论（statistical learning theory）：探索统计学习方法的有效性与效率、基本理论问题。
- 统计学习应用（application of statistical learning）：将统计学习方法应用到实际问题中去，解决实际问题。

### 1.6 统计学习的重要性

统计学习已被成功地应用到人工智能、模式识别、数据挖掘、自然语言处理、语音识别、图像识别、信息检索和生物信息等许多计算机应用领域中，并且成为这些领域的核心技术。

统计学习学科在科学技术中的重要性主要体现在以下几个方面：

1. 统计学习方法是处理海量数据的有效方法。我们处于一个信息爆炸的时代，海量数据的处理与利用是人们必然的需求。现实中的数据不但规模大，而且常常具有不确定性，统计学习往往是处理这类数据最强有力的工具。
2. 统计学习是计算机智能化的有效手段。智能化是计算机发展的必然趋势，也是计算机技术研究与开发的主要目标。近几十年来，人工智能等领域的研究表明，利用统计学习模仿人类智能的方法，虽有一定的局限性，但仍然是实现这一目标的最有效手段。
3. 统计学习是计算机科学发展的一个重要组成部分。可以认为计算机科学由三维组成：系统、计算、信息。统计学习主要属于信息这一维，并在其中起着核心作用。

## 2. 监督学习

 监督学习的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测(这里的输入、输出是指某个系统的输入与输出，不是学习的输入和输出)。

计算机的基本操作就是给定一个输入产生一个输出，所以监督学习是极其重要的统计学习分支，也是统计学习中内容最丰富、应用最广泛的部分。

### 2.1 基本概念

#### 2.1.1 输入空间、特征空间与输出空间

在监督学习中，将输入与输出所有可能取值的集合分别称为**输入空间(input space)**与**输出空间(output space)**。

输入与输出空间可以是有限元素的集合，也可以是整个欧式空间。

输入空间与输出空间可以是同一个空间，也可以是不同的空间，但通常输入空间远远大于输出空间。

每个具体的输入是一个实例(instance)，通常由特征向量(feature vector)表示。这时，所有特征向量存在的空间称为特征空间(feature space)。特征空间的每一维对应一个特征。

- **有时假设输入空间与特征空间为相同的空间，对它们不予区分。**
- **有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。**

模型实际上都是定义在特征空间上的。

在监督学习过程中，将输入与输出看作是定义在输入(特征)空间与输出空间上的随机变量的取值。

- 输入输出变量用大写字母表示，习惯上输入变量写作$X$，输出变量写作$Y$
- 输入输出变量所取的值用小写字母表示，输入变量的取值写作$x$，输出变量的取值写作$y$
- 变量可以是标量或向量，都用相同类型字母表示

输入实例$x$的特征向量记做

$x=(x^{(1)}, x^{(2)},\dots, x^{(i)},\dots,x^{(n)})^{T}$，其中，$x^{(i)}$表示$x$的第$i$个特征。

**注意：$ x^{(i)}$与$x_{i}$不同，本书通常用$x_{i}$表示多个输入变量中的第$i$个，即**$x_{i}=(x^{(1)}_{i}, x^{(2)}_{i},\dots, x^{(i)}_{i},\dots,x^{(n)}_{i})^{T}$

监督学习从训练数据(training data)集合中学习模型，对测试数据(test data)进行预测。训练数据由输入(或特征向量)与输出对组成，训练集通常表示为：$T=\{(x_{1},y_{1}),(x_{2},y_{2}),\dots,(x_{N},y_{N})\}$

测试数据也由相应的输入与输出对组成。输入与输出对又称为样本(sample)或样本点。

输入变量$X$和输出变量$Y$有不同的类型，可以是连续的，也可以是离散的。

人们根据输入、输出变量的不同类型，对预测任务给予不同的名称：

- 输入变量与输出变量均为连续变量的预测问题称为**回归问题**
- 输入变量为有限个离散变量的预测问题称为**分类问题**
- 输入变量与输出变量均为变量序列的预测问题称为**标注问题**

#### 2.1.2 联合概率分布

监督学习假设输入与输出的随机变量$X$和$Y$遵循联合概率分布$P(X,Y)$，$P(X,Y)$表示分布函数，或分布密度函数。

**注意：在学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的**

训练数据与测试数据被看作是依联合概率分布$P(X,Y)$独立同分布产生的。统计学习假设数据存在一定的统计规律，$X$和$Y$具有联合概率分布的假设就是监督学习关于数据的基本假设。

#### 2.1.3 假设空间

监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。学习的目的就在于找到最好的这样的模型。

模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间(hypothesis space)。假设空间的确定意味着学习范围的确定。

监督学习的模型可以是概率模型或非概率模型，由条件概率分布$P(Y|X)$或决策函数(decision function)$Y=f(X)$表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作$P(y|x)$或$y=f(x)$。

### 2.2 问题的形式化

监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测(prediction)。

由于在这个过程中需要训练数据集，而训练数据集往往是人工给出的，所以称为监督学习。

监督学习分为**学习**和**预测**两个过程，由学习系统与预测系统完成，如图1.1描述。

<img src="./images/图1.1 监督学习问题.png" width=50%>

首先给定一个训练数据集：$T=\{(x_{1},y_{1}),(x_{2},y_{2}),\dots,(x_{N},y_{N})\}$

其中$(x_{i},y_{i})$，$i=1,2,\dots,N$，称为样本或样本点。$x_{i}\in{X}\subseteq\textbf{R}^{n}$是输入的观测值，也称为输入或实例，$y_{i}\in{Y}$是输出的观测值，也称为输出。

监督学习中，假设训练数据与测试数据是依联合概率分布$P(X,Y)$独立同分布产生的。

在学习过程中，学习系统利用给定的训练数据集，通过学习(或训练)得到一个模型，表示为条件概率分布$\hat{P}(Y|X)$或决策函数$Y=\hat{f}(X)$。条件概率分布$\hat{P}(Y|X)$或决策函数$Y=\hat{f}(X)$描述输入与输出随机变量之间的映射关系。

在预测过程中，预测系统对于给定的测试样本集中的输入$x_{N+1}$，

由模型$y_{N+1}=\arg \max \limits_{y_{N+1}} \hat{P}(y_{N+1}|x_{N+1})$或$y_{N+1}=\hat{f}(x_{N+1})$给出相应的输出$y_{n+1}$

在学习过程中，学习系统(即学习算法)试图通过训练数据集中的样本$(x_{i},y_{i})$带来的信息学习模型。

具体地说，对输入$x_{i}$，一个具体的模型$y=f(x)$可以产生一个输出$f(x_{i})$，而训练数据集中对应的输出是$y_{i}$，如果这个模型有很好的预测能力，训练样本输出$y_i$和模型输出$f(x_{i})$之间的差就应该足够小。

学习系统通过不断的尝试，选取最好的模型，以便对训练数据集有足够好的预测，同时对未知的测试数据集的预测也有尽可能好的推广。

## 3. 统计学习三要素

















